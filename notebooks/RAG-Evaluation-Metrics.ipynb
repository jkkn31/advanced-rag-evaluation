{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bRFR6fY5Y22f"
   },
   "source": [
    "# Assignment: Calculating and Reporting Metrics of the RAG Pipeline\n",
    "----\n",
    "* Name: Krishnakanth Naik Jarapala\n",
    "* NUID: 002724795\n",
    "---- \n",
    "In this quickstart guide, you will learn\n",
    "- to create a RAG (Retrieval-Augmented Generation) model from scratch.\n",
    "- Log the modelâ€™s performance.\n",
    "- Obtain feedback on responses generated by an LLM (Language Model).\n",
    "- Evaluation: Utilize the \"hallucination triad\" for evaluation, focusing on groundedness, context relevance, and answer relevance.\n",
    "- Optimization: to Improve the efficiency of the RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Jc6EMvmqY22o"
   },
   "outputs": [],
   "source": [
    "# ! pip install trulens_eval chromadb openai llama-index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "VUoUdYlBY22s"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Please use your own OpenAI API Key\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IGnMjjWYY22u"
   },
   "source": [
    "## Load Sample Data\n",
    "\n",
    "In this case, we'll just initialize some simple text in the notebook to reduce the OpenAI api cost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "I99XI2wGY22u"
   },
   "outputs": [],
   "source": [
    "info_1 = \"\"\"\n",
    "The University of Washington, established in 1861 in Seattle, is a public research university with over 45,000 students across three campuses: \n",
    "Seattle, Tacoma, and Bothell. As the flagship institution of Washington's six public universities, UW comprises more than 500 buildings and \n",
    "20 million square feet of space, including one of the largest library systems globally.\n",
    "\"\"\"\n",
    "\n",
    "info_2 = \"\"\"\n",
    "Washington State University (WSU), founded in 1890, is a public research university located in Pullman, Washington. With multiple campuses statewide, \n",
    "it is the second largest institution of higher education in the state. WSU is renowned for its programs in veterinary medicine, agriculture, engineering,\n",
    "architecture, and pharmacy.\n",
    "\"\"\"\n",
    "\n",
    "info_3 = \"\"\"\n",
    "Seattle, located on Puget Sound in the Pacific Northwest, is surrounded by water, mountains, and evergreen forests, featuring thousands of acres of \n",
    "parkland. The city is a hub for the tech industry, with Microsoft and Amazon headquartered in its metropolitan area. Its most iconic landmark is the \n",
    "futuristic Space Needle, a legacy of the 1962 World's Fair.\n",
    "\"\"\"\n",
    "\n",
    "info_4 = \"\"\"\n",
    "Starbucks Corporation, an American multinational chain of coffeehouses and roastery reserves, is headquartered in Seattle, Washington. As the world's\n",
    "largest coffeehouse chain, Starbucks represents the United States' second wave of coffee culture.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QtLKDb5BY22w"
   },
   "source": [
    "## Create Vector Store\n",
    "\n",
    "Create a chromadb vector store in memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "jKI9dZfsY22w"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import chromadb\n",
    "from chromadb.utils.embedding_functions import OpenAIEmbeddingFunction\n",
    "\n",
    "embedding_function = OpenAIEmbeddingFunction(api_key=os.environ.get('OPENAI_API_KEY'),\n",
    "                                             model_name=\"text-embedding-ada-002\")\n",
    "\n",
    "\n",
    "chroma_client = chromadb.Client()\n",
    "vector_store = chroma_client.get_or_create_collection(name=\"sample-data-to-evaluate\",\n",
    "                                                      embedding_function=embedding_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "cVIj_hwpY22y"
   },
   "outputs": [],
   "source": [
    "#### Populate the vector store.\n",
    "vector_store.add(\"info_1\", documents=info_1)\n",
    "vector_store.add(\"info_2\", documents=info_2)\n",
    "vector_store.add(\"info_3\", documents=info_3)\n",
    "vector_store.add(\"info_4\", documents=info_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2gaUeyDSY22z"
   },
   "source": [
    "## Building a RAG Model from Scratch\n",
    "\n",
    "### Step 1: Create a Custom RAG Model\n",
    "\n",
    "In this section, you'll learn how to build a custom Retrieval-Augmented Generation (RAG) model from the ground up. This involves setting up your data sources, designing the retrieval mechanism, and integrating it with a generative model to create a seamless RAG pipeline.\n",
    "\n",
    "### Step 2: Integrate TruLens Custom Instrumentation\n",
    "\n",
    "After constructing your RAG model, we'll enhance it by incorporating TruLens custom instrumentation. This integration allows for advanced logging and monitoring of the modelâ€™s performance, enabling you to track metrics, debug issues, and gather valuable feedback on the responses generated by your language model. \n",
    "\n",
    "### Detailed Steps:\n",
    "\n",
    "1. **Set Up Your Data Sources:**\n",
    "   - Identify and prepare the datasets that your RAG model will use for retrieval.\n",
    "   - Ensure the data is clean, well-structured, and relevant to your use case.\n",
    "\n",
    "2. **Design the Retrieval Mechanism:**\n",
    "   - Implement a retrieval system that efficiently indexes and searches your data.\n",
    "   - Optimize the retrieval process to quickly find the most relevant information for the input queries.\n",
    "\n",
    "3. **Integrate with a Generative Model:**\n",
    "   - Connect your retrieval system to a generative language model.\n",
    "   - Design the interaction between retrieval and generation to ensure the model produces coherent and contextually accurate responses.\n",
    "\n",
    "4. **Add TruLens Instrumentation:**\n",
    "   - Incorporate TruLens to log key performance metrics.\n",
    "   - Use TruLens to monitor the groundedness, context relevance, and answer relevance of the generated responses.\n",
    "   - Set up alerts and dashboards to track the modelâ€™s performance over time and make data-driven improvements.\n",
    "\n",
    "By following these steps, you'll build a robust and well-instrumented RAG model capable of delivering high-quality, relevant responses in your application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "GChkOUgPY220",
    "outputId": "19d44d83-2846-40c1-a150-68a911e9f763"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¦‘ Tru initialized with db url sqlite:///default.sqlite .\n",
      "ðŸ›‘ Secret keys may be written to the database. See the `database_redact_keys` option of `Tru` to prevent this.\n"
     ]
    }
   ],
   "source": [
    "from trulens_eval import Tru\n",
    "from trulens_eval.tru_custom_app import instrument\n",
    "tru = Tru()\n",
    "tru.reset_database()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "oizF9gFHY221"
   },
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "oai_client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "1X2EkdhQY222"
   },
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "oai_client = OpenAI()\n",
    "\n",
    "class build_a_RAG:\n",
    "    @instrument\n",
    "    def retrieve(self, query: str) -> list:\n",
    "        \"\"\"\n",
    "        Retrieve relevant text from vector store.\n",
    "        \"\"\"\n",
    "        results = vector_store.query(\n",
    "            query_texts=query,\n",
    "            n_results=4\n",
    "        )\n",
    "        # Flatten the list of lists into a single list\n",
    "        return [doc for sublist in results['documents'] for doc in sublist]\n",
    "\n",
    "    @instrument\n",
    "    def generate_completion(self, query: str, context_str: list) -> str:\n",
    "        \"\"\"\n",
    "        Generate answer from context.\n",
    "        \"\"\"\n",
    "        completion = oai_client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        temperature=0,\n",
    "        messages=\n",
    "        [\n",
    "            {\"role\": \"user\",\n",
    "            \"content\":\n",
    "            f\"We have provided context information below. \\n\"\n",
    "            f\"---------------------\\n\"\n",
    "            f\"{context_str}\"\n",
    "            f\"\\n---------------------\\n\"\n",
    "            f\"Given this information, please answer the question: {query}\"\n",
    "            }\n",
    "        ]\n",
    "        ).choices[0].message.content\n",
    "        return completion\n",
    "\n",
    "    @instrument\n",
    "    def query(self, query: str) -> str:\n",
    "        context_str = self.retrieve(query)\n",
    "        completion = self.generate_completion(query, context_str)\n",
    "        return completion\n",
    "\n",
    "rag = build_a_RAG()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1mfFMAmfY222"
   },
   "source": [
    "## Setting Up Feedback Functions\n",
    "\n",
    "### Step 1: Define Feedback Functions\n",
    "\n",
    "In this section, we will establish feedback functions that evaluate the performance of our RAG model. These functions will help us detect hallucinations by assessing three key metrics: groundedness, answer relevance, and context relevance.\n",
    "\n",
    "### Detailed Steps:\n",
    "\n",
    "1. **Groundedness:**\n",
    "   - **Purpose:** Ensure that the generated responses are based on factual and verifiable information.\n",
    "   - **Implementation:** Create a function that cross-references the model's outputs with the original data sources to verify their accuracy. This function will check if the information provided by the model can be traced back to a reliable source within the dataset.\n",
    "\n",
    "2. **Answer Relevance:**\n",
    "   - **Purpose:** Ensure that the responses are directly addressing the input queries.\n",
    "   - **Implementation:** Develop a function that measures how well the generated responses align with the specific questions or prompts. This function will compare the key elements of the query with the response to determine if the model is providing relevant and focused answers.\n",
    "\n",
    "3. **Context Relevance:**\n",
    "   - **Purpose:** Ensure that the responses are appropriate and coherent within the given context.\n",
    "   - **Implementation:** Create a function that evaluates the contextual accuracy of the responses. This function will analyze whether the generated content makes sense within the broader conversation or context, maintaining logical consistency and relevance to preceding information.\n",
    "\n",
    "### Step 2: Integrate Feedback Functions\n",
    "\n",
    "Once the feedback functions are defined, integrate them into the RAG modelâ€™s evaluation pipeline. This will enable continuous monitoring and refinement of the modelâ€™s outputs, ensuring high-quality and reliable responses. \n",
    "\n",
    "By setting up these feedback functions, you will be able to systematically detect and address hallucinations in your RAG model, improving its overall accuracy and effectiveness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "w8DQGRQWY223",
    "outputId": "22e2eb31-0fb6-407d-d1c7-0bb7f36f6075"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… In Groundedness, input source will be set to __record__.app.retrieve.rets.collect() .\n",
      "âœ… In Groundedness, input statement will be set to __record__.main_output or `Select.RecordOutput` .\n",
      "âœ… In Answer Relevance, input prompt will be set to __record__.main_input or `Select.RecordInput` .\n",
      "âœ… In Answer Relevance, input response will be set to __record__.main_output or `Select.RecordOutput` .\n",
      "âœ… In Context Relevance, input question will be set to __record__.main_input or `Select.RecordInput` .\n",
      "âœ… In Context Relevance, input context will be set to __record__.app.retrieve.rets[:] .\n"
     ]
    }
   ],
   "source": [
    "from trulens_eval import Feedback, Select\n",
    "from trulens_eval.feedback.provider.openai import OpenAI\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "provider = OpenAI(model_engine=\"gpt-4o\")\n",
    "\n",
    "# Define a groundedness feedback function\n",
    "f_groundedness = (\n",
    "    Feedback(provider.groundedness_measure_with_cot_reasons, name = \"Groundedness\")\n",
    "    .on(Select.RecordCalls.retrieve.rets.collect())\n",
    "    .on_output()\n",
    ")\n",
    "# Question/answer relevance between overall question and answer.\n",
    "f_answer_relevance = (\n",
    "    Feedback(provider.relevance_with_cot_reasons, name = \"Answer Relevance\")\n",
    "    .on_input()\n",
    "    .on_output()\n",
    ")\n",
    "\n",
    "# Context relevance between question and each context chunk.\n",
    "f_context_relevance = (\n",
    "    Feedback(provider.context_relevance_with_cot_reasons, name = \"Context Relevance\")\n",
    "    .on_input()\n",
    "    .on(Select.RecordCalls.retrieve.rets[:])\n",
    "    .aggregate(np.mean) # choose a different aggregation method if you wish\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5HTZGUZcY224"
   },
   "source": [
    "## Construct the App\n",
    "\n",
    "1. **Wrap the Custom RAG:**\n",
    "   - Integrate your custom RAG model using TruCustomApp for streamlined deployment.\n",
    "2. **Add Feedback Mechanisms:**\n",
    "   - Implement a list of feedback functions to evaluate and improve model performance.\n",
    "3. **Set Up Evaluation:**\n",
    "   - Configure TruCustomApp to utilize the feedback functions for continuous evaluation and refinement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "m5_MwRXOY224"
   },
   "outputs": [],
   "source": [
    "from trulens_eval import TruCustomApp\n",
    "\n",
    "# 1. Wrap the Custom RAG\n",
    "\n",
    "tru_rag = TruCustomApp(rag,\n",
    "    app_id = 'Simple RAG',\n",
    "    feedbacks = [f_groundedness, f_answer_relevance, f_context_relevance])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ArgJ4o9tY224"
   },
   "source": [
    "#### Inference\n",
    "Use `tru_rag` as a context manager for the custom RAG-from-scratch app."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "-uJok9qtY225"
   },
   "outputs": [],
   "source": [
    "with tru_rag as recording:\n",
    "    rag.query(\"When was the University of Washington established?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9-bgSNL_Y225"
   },
   "source": [
    "### Review Results - Check the leaderboard to view the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "QspIzau2Y225",
    "outputId": "33d970cb-7d6e-430e-d77a-0addba7bfce4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Context Relevance</th>\n",
       "      <th>Groundedness</th>\n",
       "      <th>Answer Relevance</th>\n",
       "      <th>latency</th>\n",
       "      <th>total_cost</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>app_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Simple RAG</th>\n",
       "      <td>0.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.00048</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Context Relevance  Groundedness  Answer Relevance  latency  \\\n",
       "app_id                                                                   \n",
       "Simple RAG               0.25           1.0               1.0      6.0   \n",
       "\n",
       "            total_cost  \n",
       "app_id                  \n",
       "Simple RAG     0.00048  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tru.get_leaderboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "gazvP82KY225",
    "outputId": "eef0829b-98a9-491c-b69c-dcf0669346d1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>context</th>\n",
       "      <th>ret</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>When was the University of Washington establis...</td>\n",
       "      <td>\\nThe University of Washington, established in...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>When was the University of Washington establis...</td>\n",
       "      <td>\\nWashington State University (WSU), founded i...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>When was the University of Washington establis...</td>\n",
       "      <td>\\nSeattle, located on Puget Sound in the Pacif...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>When was the University of Washington establis...</td>\n",
       "      <td>\\nStarbucks Corporation, an American multinati...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  When was the University of Washington establis...   \n",
       "1  When was the University of Washington establis...   \n",
       "2  When was the University of Washington establis...   \n",
       "3  When was the University of Washington establis...   \n",
       "\n",
       "                                             context  ret  \n",
       "0  \\nThe University of Washington, established in...  1.0  \n",
       "1  \\nWashington State University (WSU), founded i...  0.0  \n",
       "2  \\nSeattle, located on Puget Sound in the Pacif...  0.0  \n",
       "3  \\nStarbucks Corporation, an American multinati...  0.0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_record = recording.records[-1]\n",
    "\n",
    "from trulens_eval.utils.display import get_feedback_result\n",
    "get_feedback_result(last_record, \"Context Relevance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mLZ5cYoFY226"
   },
   "source": [
    "## Implement Guardrails\n",
    "\n",
    "To enhance efficiency and reduce hallucinations, use feedback results as guardrails during inference. Specifically, **apply the context relevance score to filter out irrelevant contexts before they reach the LLM**. \n",
    "\n",
    "Rebuild your RAG by using the `@context-filter` decorator on the filtering method, and set the feedback function and threshold for effective guardrailing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "AcqAQKoTY226"
   },
   "outputs": [],
   "source": [
    "# note: feedback function used for guardrail must only return a score, not also reasons\n",
    "f_context_relevance_score = (\n",
    "    Feedback(provider.context_relevance, name = \"Context Relevance\")\n",
    ")\n",
    "\n",
    "from trulens_eval.guardrails.base import context_filter\n",
    "\n",
    "class filtered_RAG_from_scratch:\n",
    "    @instrument\n",
    "    @context_filter(f_context_relevance_score, 0.75, keyword_for_prompt=\"query\")\n",
    "    def retrieve(self, query: str) -> list:\n",
    "        \"\"\"\n",
    "        Retrieve relevant text from vector store.\n",
    "        \"\"\"\n",
    "        results = vector_store.query(\n",
    "        query_texts=query,\n",
    "        n_results=4\n",
    "    )\n",
    "        return [doc for sublist in results['documents'] for doc in sublist]\n",
    "\n",
    "    @instrument\n",
    "    def generate_completion(self, query: str, context_str: list) -> str:\n",
    "        \"\"\"\n",
    "        Generate answer from context.\n",
    "        \"\"\"\n",
    "        completion = oai_client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        temperature=0,\n",
    "        messages=\n",
    "        [\n",
    "            {\"role\": \"user\",\n",
    "            \"content\":\n",
    "            f\"We have provided context information below. \\n\"\n",
    "            f\"---------------------\\n\"\n",
    "            f\"{context_str}\"\n",
    "            f\"\\n---------------------\\n\"\n",
    "            f\"Given this information, please answer the question: {query}\"\n",
    "            }\n",
    "        ]\n",
    "        ).choices[0].message.content\n",
    "        return completion\n",
    "\n",
    "    @instrument\n",
    "    def query(self, query: str) -> str:\n",
    "        context_str = self.retrieve(query=query)\n",
    "        completion = self.generate_completion(query=query, context_str=context_str)\n",
    "        return completion\n",
    "\n",
    "filtered_rag = filtered_RAG_from_scratch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "epDappkmY226"
   },
   "source": [
    "## Build Filtered-Context RAG to improve the efficiency of the retrival "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "zmdYBxtlY226"
   },
   "outputs": [],
   "source": [
    "from trulens_eval import TruCustomApp\n",
    "\n",
    "# 2. Filtered-Context - RAG\n",
    "\n",
    "filtered_tru_rag = TruCustomApp(filtered_rag,\n",
    "    app_id = 'Filtered Context - RAG',\n",
    "    feedbacks = [f_groundedness, f_answer_relevance, f_context_relevance])\n",
    "\n",
    "\n",
    "# 3. Lets check the Model Responses.\n",
    "with filtered_tru_rag as recording:\n",
    "    filtered_rag.query(query=\"when was the university of washington founded?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "2ZiFMNefY227",
    "outputId": "3c3e211b-0358-4d0b-f30b-086efb2753c2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Context Relevance</th>\n",
       "      <th>Groundedness</th>\n",
       "      <th>Answer Relevance</th>\n",
       "      <th>latency</th>\n",
       "      <th>total_cost</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>app_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Filtered Context - RAG</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.024872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Simple RAG</th>\n",
       "      <td>0.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.000480</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Context Relevance  Groundedness  Answer Relevance  \\\n",
       "app_id                                                                      \n",
       "Filtered Context - RAG               1.00           1.0               1.0   \n",
       "Simple RAG                           0.25           1.0               1.0   \n",
       "\n",
       "                        latency  total_cost  \n",
       "app_id                                       \n",
       "Filtered Context - RAG      6.0    0.024872  \n",
       "Simple RAG                  6.0    0.000480  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tru.get_leaderboard(app_ids=[])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rPiV0sAiY227"
   },
   "source": [
    "## Experience the effectiveness of filtering!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "lhGAOnfKY228",
    "outputId": "b023c2b1-710c-439d-a6f3-0eca1a6004f8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>context</th>\n",
       "      <th>ret</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>when was the university of washington founded?</td>\n",
       "      <td>\\nThe University of Washington, established in...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         question  \\\n",
       "0  when was the university of washington founded?   \n",
       "\n",
       "                                             context  ret  \n",
       "0  \\nThe University of Washington, established in...  1.0  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Here is the Sample record of Context Relevance.\n",
    "last_record = recording.records[-1]\n",
    "\n",
    "from trulens_eval.utils.display import get_feedback_result\n",
    "get_feedback_result(last_record, \"Context Relevance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "008c8387461047f9a05d09e92758e3fb"
     ]
    },
    "id": "XcbyQmdWY229",
    "outputId": "e23d5131-b929-4033-86b9-9422349dead9"
   },
   "outputs": [],
   "source": [
    "# tru.run_dashboard(port=3453, force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Dq9jwV2LY229"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
